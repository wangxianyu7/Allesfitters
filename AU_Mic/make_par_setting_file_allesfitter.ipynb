{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "dat_files = [x for x in os.listdir() if x.endswith('.dat') and not x.startswith('.')]\n",
    "\n",
    "for dat_file in dat_files:\n",
    "    time, flux, flux_err = np.loadtxt(dat_file, unpack=True)\n",
    "    splited_dat_name = dat_file.split('.')\n",
    "    rename = '.'.join([splited_dat_name[0], splited_dat_name[2], splited_dat_name[1],'csv'])\n",
    "    np.savetxt(rename, np.array([time, flux, flux_err]).T, delimiter=',', header='#time,flux,flux_err', comments='', fmt='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "parameter = {}\n",
    "parameter['b_rr'] = 0.0488\n",
    "rr = parameter['b_rr']\n",
    "ar = 18.79\n",
    "t0 = 2458525.04109\n",
    "period = 8.46308\n",
    "\n",
    "b_rsuma = (1+rr)/ar\n",
    "parameter['b_rsuma'] = b_rsuma\n",
    "parameter['b_cosi'] = 0\n",
    "parameter['b_epoch'] = t0\n",
    "parameter['b_period'] = period\n",
    "parameter['b_K'] = 0.396\n",
    "parameter['b_f_c'] = 0\n",
    "parameter['b_f_s'] = 0\n",
    "parameter['host_lambda'] = 0\n",
    "parameter['host_vsini'] = 8.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TESS.LC']\n",
      "###############################################################################,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_params(parameter, inst_phot, inst_rv, inst_rm):\n",
    "    rr = parameter['b_rr']; rsuma = parameter['b_rsuma']; cosi = parameter['b_cosi']; epoch = parameter['b_epoch']; period = parameter['b_period']; k = parameter['b_K']; f_c = parameter['b_f_c']; f_s = parameter['b_f_s']\n",
    "    ### print\n",
    "\n",
    "    with open('params.csv', 'w') as f:\n",
    "        print('#name,value,fit,bounds,label,unit,coupled_with', file=f)\n",
    "        print('#baselines,,,,,,', file=f)\n",
    "\n",
    "        print('b_rr,'+str(rr)+',1,uniform 0 1,$R_b / R_\\star$,,', file=f)\n",
    "        print('b_rsuma,'+str(rsuma)+',1,uniform 0 1,$(R_\\star + R_b) / a_b$,,', file=f)\n",
    "        print('b_cosi,'+str(cosi)+',1,uniform 0 1,$\\cos{i_b}$,,', file=f)\n",
    "        print('b_epoch,'+str(epoch)+',1,uniform '+str(epoch-1)+' '+str(epoch+1)+',$t_0$,HJDUTC,', file=f)\n",
    "        print('b_period,'+str(period)+',1,uniform 0 100,$P_b$,d,', file=f)\n",
    "        print('b_K,'+str(k)+',1,uniform 0 2,$K_b$,km/s,', file=f)\n",
    "        print('b_f_c,'+str(f_c)+',1,uniform -1.0 1.0,$\\sqrt{e_b} \\cos{\\omega_b}$,,', file=f)\n",
    "        print('b_f_s,'+str(f_s)+',1,uniform -1.0 1.0,$\\sqrt{e_b} \\sin{\\omega_b}$,,', file=f)\n",
    "\n",
    "\n",
    "        ### dilution\n",
    "        print('#dilution per instrument,,,,,', file=f)\n",
    "        # for ele in inst_phot:\n",
    "        #     print('dil_'+ele+','+str(parameter['dil_'+ele])+',1,uniform 0 1,$dilution_\\mathrm{'+ele+'}$,,')\n",
    "        ### ld\n",
    "        print('#limb darkening coefficients per instrument,,,,,', file=f)\n",
    "        for ele in inst_rm:\n",
    "            # band = ele.split('_')[-1]\n",
    "            # print(band)\n",
    "            print('host_ldc_q1_'+ele+','+str(parameter['host_ldc_q1_'+ele])+',1,uniform 0 1,$q_{1;\\mathrm{'+ele+'}}$,,', file=f)\n",
    "            print('host_ldc_q2_'+ele+','+str(parameter['host_ldc_q2_'+ele])+',1,uniform 0 1,$q_{2;\\mathrm{'+ele+'}}$,,', file=f)\n",
    "            \n",
    "            \n",
    "            data = np.loadtxt(ele+'.csv',delimiter=',')\n",
    "            rv = data[:,1]\n",
    "            med_rv = np.median(rv)\n",
    "            \n",
    "            ## baseline\n",
    "            # print('baseline_gp_offset_rv_'+ele+',0,1,uniform '+str(med_rv-1)+' '+str(med_rv+1)+',$\\mathrm{gp offset ('+ele+')}$,,', file=f)\n",
    "            # print('baseline_gp_matern32_lnsigma_rv_'+ele+',-5,1,uniform -15 0,$\\mathrm{gp ln sigma ('+ele+')}$,,', file=f)\n",
    "            # print('baseline_gp_matern32_lnrho_rv_'+ele+',0,1,uniform -1 15,$\\mathrm{gp ln rho ('+ele+')}$,,', file=f)\n",
    "# baseline_gp_offset_flux_Leonardo,0,1,uniform -0.01 0.01,$\\mathrm{gp ln sigma (Leonardo)}$,\n",
    "# baseline_gp_matern32_lnsigma_flux_Leonardo,-5,1,uniform -15 0,$\\mathrm{gp ln sigma (Leonardo)}$,\n",
    "# baseline_gp_matern32_lnrho_flux_Leonardo,0,1,uniform -1 15,$\\mathrm{gp ln rho (Leonardo)}$,\n",
    "\n",
    "        \n",
    "\n",
    "        bands = np.asarray([x.split('.')[1] for x in inst_phot])\n",
    "        unique_bands = np.unique(bands)\n",
    "            \n",
    "\n",
    "        for band in unique_bands:\n",
    "            idx = np.where(bands == band)[0]\n",
    "            for count_band,i in enumerate(idx):\n",
    "                if count_band>0:\n",
    "                    print('host_ldc_q1_'+inst_phot[i]+',,,,,,'+'host_ldc_q1_'+inst_phot[idx[0]], file=f)\n",
    "                    print('host_ldc_q2_'+inst_phot[i]+',,,,,,'+'host_ldc_q2_'+inst_phot[idx[0]], file=f)\n",
    "                else:\n",
    "                    print('host_ldc_q1_'+inst_phot[i]+','+str(parameter['host_ldc_q1_'+inst_phot[i]])+',1,uniform 0 1,$q_{1;\\mathrm{'+inst_phot[i]+'}}$,,', file=f)\n",
    "                    print('host_ldc_q2_'+inst_phot[i]+','+str(parameter['host_ldc_q2_'+inst_phot[i]])+',1,uniform 0 1,$q_{2;\\mathrm{'+inst_phot[i]+'}}$,,', file=f)\n",
    "        # ldc_q1_HAT-P-1_56_TESS,,,,,,\n",
    "        print('#errors per instrument,', file=f)\n",
    "        \n",
    "        no_tess_inst_phot = np.asarray([x for x in inst_phot if 'TESS' not in x])\n",
    "        tess_inst_phot = np.asarray([x for x in inst_phot if 'TESS' in x])\n",
    "        print(inst_phot)\n",
    "        for ele in no_tess_inst_phot:\n",
    "            print('ln_err_flux_'+ele+','+str(parameter['ln_err_flux_'+ele])+',1,uniform -15 0.0,$\\ln{\\sigma_\\mathrm{flux; '+ele+'}}$,$\\ln{ \\mathrm{mag} }$,', file=f)\n",
    "            \n",
    "        for i,ele in enumerate(tess_inst_phot):\n",
    "            if i <1:\n",
    "                print('ln_err_flux_'+ele+','+str(parameter['ln_err_flux_'+ele])+',1,uniform -15 0.0,$\\ln{\\sigma_\\mathrm{flux; '+ele+'}}$,$\\ln{ \\mathrm{mag} }$,', file=f)\n",
    "            else:\n",
    "                print('ln_err_flux_'+ele+',,,,,,ln_err_flux_'+tess_inst_phot[0], file=f)            \n",
    "            \n",
    "            \n",
    "            \n",
    "        for ele in np.append(inst_rm, inst_rv):\n",
    "            print('ln_jitter_rv_'+ele+','+str(parameter['ln_jitter_rv_'+ele])+',1,uniform -15 0.0,$\\ln{\\sigma_\\mathrm{rv; '+ele+'}}$,$\\ln{ \\mathrm{km/s} }$,', file=f)\n",
    "        print('### lambda and vsini', file=f)\n",
    "        print('host_lambda,'+str(parameter['host_lambda'])+',1,uniform -360 360,$\\lambda_\\mathrm{host}$,,', file=f)\n",
    "        print('host_vsini,'+str(parameter['host_vsini'])+',1,normal '+str(parameter['host_vsini'])+' 1.5,$v\\sin{i}_\\mathrm{host}$,$\\mathrm{km/s}$,', file=f)\n",
    "              #0 100,$v\\sin{i}_\\mathrm{host}$,$\\mathrm{km/s}$,', file=f)\n",
    "# make_params(parameter)\n",
    "### setting \n",
    "\n",
    "# name,value\n",
    "# ##############################################################################,\n",
    "# General settings,\n",
    "# ##############################################################################,\n",
    "\n",
    "def make_settings(inst_phot, inst_rv, inst_rm):\n",
    "    with open('settings.csv','w') as f:\n",
    "\n",
    "        print('names,values',file=f)\n",
    "        print('##############################################################################,',file=f)\n",
    "        print('### General settings',file=f)\n",
    "        print('##############################################################################,',file=f)\n",
    "\n",
    "        # companions_phot,b\n",
    "        # companions_rv,b\n",
    "        # inst_phot,Wise_I_4069_LC_HJDUTC merged_GUNNZ_LC_HJDUTC merged_Sloanz_LC_HJDUTC\n",
    "        # inst_rv,HDS_RV_HJDUTC HDS_RM_HJDUTC HIRES_RM_HJDUTC\n",
    "        print('companions_phot,b',file=f)\n",
    "        print('companions_rv,b',file=f)\n",
    "        print('inst_phot,',end='',file=f)\n",
    "        for ele in inst_phot:\n",
    "            print(ele,end=' ',file=f)\n",
    "        print(file=f)\n",
    "        print('inst_rv,',end='',file=f)\n",
    "        for ele in np.append(inst_rm, inst_rv):\n",
    "            print(ele,end=' ',file=f)\n",
    "        print(file=f)\n",
    "        print('''###############################################################################,\n",
    "# Fit performance settings,\n",
    "###############################################################################,\n",
    "multiprocess,True\n",
    "multiprocess_cores,all\n",
    "fast_fit,True\n",
    "fast_fit_width,0.3333333333333333\n",
    "secondary_eclipse,False\n",
    "phase_curve,False\n",
    "shift_epoch,True\n",
    "inst_for_b_epoch,all''',file=f)\n",
    "        print('''###############################################################################,\n",
    "# MCMC settings,\n",
    "###############################################################################,\n",
    "mcmc_nwalkers,100\n",
    "mcmc_total_steps,10000\n",
    "mcmc_burn_steps,1000\n",
    "#mcmc_thin_by,10\n",
    "#mcmc_pre_run_loops,2\n",
    "#mcmc_pre_run_steps,1000\n",
    "mcmc_total_steps_over_max_tau,50\n",
    "de_steps,5000\n",
    "###############################################################################,\n",
    "# Nested Sampling settings,\n",
    "###############################################################################,\n",
    "ns_modus,dynamic\n",
    "ns_nlive,500\n",
    "ns_bound,single\n",
    "ns_sample,rwalk\n",
    "ns_tol,0.01''',file=f)\n",
    "        print('''###############################################################################,\n",
    "# Limb darkening law per object and instrument,\n",
    "# if 'lin' one corresponding parameter called 'ldc_q1_inst' has to be given in params.csv,\n",
    "# if 'quad' two corresponding parameter called 'ldc_q1_inst' and 'ldc_q2_inst' have to be given in params.csv,\n",
    "# if 'sing' three corresponding parameter called 'ldc_q1_inst'; 'ldc_q2_inst' and 'ldc_q3_inst' have to be given in params.csv,\n",
    " ###############################################################################,''',file=f)\n",
    "        for ele in np.append(inst_phot, inst_rm):\n",
    "            print('host_ld_law_'+ele+',quad',file=f)\n",
    "        print('''###############################################################################,\n",
    "# Baseline settings per instrument,\n",
    "# baseline params per instrument: sample_offset / sample_linear / sample_GP / hybrid_offset / hybrid_poly_1 / hybrid_poly_2 / hybrid_poly_3 / hybrid_pol_4 / hybrid_spline / hybrid_GP,\n",
    "# if 'sample_offset' one corresponding parameter called 'baseline_offset_key_inst' has to be given in params.csv,\n",
    "# if 'sample_linear' two corresponding parameters called 'baseline_a_key_inst' and 'baseline_b_key_inst' have to be given in params.csv,\n",
    "# if 'sample_GP' two corresponding parameters called 'baseline_gp1_key_inst' and 'baselie_gp2_key_inst' have to be given in params.csv,\n",
    "###############################################################################,''',file=f)\n",
    "\n",
    "\n",
    "\n",
    "        for ele in inst_phot:\n",
    "            baseline = 'hybrid_offset'\n",
    "            if \"TESS\" in ele:\n",
    "                baseline = 'hybrid_offset'\n",
    "            print('baseline_flux_'+ele+','+baseline,file=f)\n",
    "        for ele in inst_rv:\n",
    "            print('baseline_rv_'+ele+',hybrid_offset',file=f)\n",
    "\n",
    "        for ele in inst_rm:\n",
    "            print('baseline_rv_'+ele+',hybrid_offset',file=f)\n",
    "\n",
    "        print('''###############################################################################,\n",
    "# Error settings per instrument,\n",
    "# errors (overall scaling) per instrument: sample / hybrid,\n",
    "# if 'sample' one corresponding parameter called 'ln_err_key_inst' (photometry) or 'ln_jitter_key_inst' (RV) has to be given in params.csv,\n",
    "###############################################################################,''',file=f)\n",
    "\n",
    "\n",
    "        for ele in inst_phot:\n",
    "            print('error_flux_'+ele+',sample',file=f)\n",
    "        for ele in inst_rv:\n",
    "            print('error_rv_'+ele+',sample',file=f)\n",
    "        print('''# TTVs,\n",
    "###############################################################################,\n",
    "fit_ttvs,False\n",
    "###############################################################################,\n",
    "# Flux weighted RVs per object and instrument,\n",
    "# (\"Yes\" for Rossiter-McLaughlin effect),\n",
    "###############################################################################,''',file=f)\n",
    "\n",
    "        for ele in inst_rm:\n",
    "            print('b_flux_weighted_'+ele+',True',file=f)\n",
    "\n",
    "        print('''###############################################################################,''')\n",
    "        for key in parameter.keys():\n",
    "            if 'exp' in key:\n",
    "                print(key,parameter[key],file=f,sep=',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# host_ldc_q1_NEID_RM\n",
    "\n",
    "\n",
    "inst_phot = [x.strip('.csv') for x in np.sort(np.asarray(glob.glob('*.csv'))) if 'RM' not in x and 'RV' not in x and 'param' not in x and 'settings' not in x]\n",
    "\n",
    "# inst_phot = [inst_phot[0], inst_phot[-7]]\n",
    "\n",
    "inst_rm = [x.strip('.csv') for x in np.sort(np.asarray(glob.glob('*.RM.csv')))]\n",
    "inst_rv = [x.strip('.csv') for x in np.sort(np.asarray(glob.glob('*.RV.csv')))]\n",
    "\n",
    "\n",
    "for inst in inst_phot+inst_rm:\n",
    "    parameter['host_ldc_q1_'+inst] = 0.5\n",
    "    parameter['host_ldc_q2_'+inst] = 0.5\n",
    "\n",
    "for inst in inst_phot+inst_rm:\n",
    "    parameter['ln_err_flux_'+inst] = -7\n",
    "\n",
    "for inst in inst_rm+inst_rv:\n",
    "    parameter['ln_jitter_rv_'+inst] = -7\n",
    "    \n",
    "    \n",
    "for inst in inst_rm:\n",
    "    data = np.loadtxt(inst+'.csv',delimiter=',')\n",
    "    t_exp = np.median(np.diff(data[:,0]))\n",
    "    t_exp_sec = t_exp*24*3600\n",
    "    if t_exp_sec > 150:\n",
    "        parameter['t_exp_'+inst] = t_exp\n",
    "        parameter['t_exp_n_int_'+inst] = 10\n",
    "\n",
    "\n",
    "make_params(parameter, inst_phot, inst_rv, inst_rm)\n",
    "make_settings(inst_phot, inst_rv, inst_rm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def _estimate_vmac_doyle2014(teff, logg, feh):\n",
    "    \"\"\"\n",
    "    Estimate Macroturbulence velocity (Vmac) by using an empirical relation\n",
    "    considering the effective temperature, surface gravity and metallicity.\n",
    "\n",
    "    The relation was constructed by Doyle et al. (2014), which is only valid\n",
    "    for the Teff range 5200 to 6400 K, and the log g range 4.0 to 4.6 dex.\n",
    "    \"\"\"\n",
    "    t0 = 5777\n",
    "    g0 = 4.44\n",
    "\n",
    "    if logg >= 3.5:\n",
    "        if teff >= 5000:\n",
    "            # main sequence and subgiants (RGB)\n",
    "            vmac = 3.21 + 2.33e-3*(teff-t0) + 2e-6*(teff-t0)**2 - 2*(logg-g0)\n",
    "        else:\n",
    "            # main sequence\n",
    "            vmac = 3.21 + 2.33e-3*(teff-t0) + 2e-6*(teff-t0)**2 - 2*(logg-g0)\n",
    "    else:\n",
    "        # Out of the calibrated limits\n",
    "        vmac = 0.\n",
    "\n",
    "    return vmac\n",
    "\n",
    "def _estimate_vmac_ges(teff, logg, feh):\n",
    "    \"\"\"\n",
    "    Estimate Microturbulence velocity (Vmic) by using an empirical relation\n",
    "    considering the effective temperature, surface gravity and metallicity.\n",
    "\n",
    "    The relation was constructed by Maria Bergemann for the Gaia ESO Survey.\n",
    "    \"\"\"\n",
    "    t0 = 5500\n",
    "    g0 = 4.0\n",
    "\n",
    "    if logg >= 3.5:\n",
    "        if teff >= 5000:\n",
    "            # main sequence and subgiants (RGB)\n",
    "            vmac = 3*(1.15 + 7e-4*(teff-t0) + 1.2e-6*(teff-t0)**2 - 0.13*(logg-g0) + 0.13*(logg-g0)**2 - 0.37*feh - 0.07*feh**2)\n",
    "        else:\n",
    "            # main sequence\n",
    "            vmac = 3*(1.15 + 2e-4*(teff-t0) + 3.95e-7*(teff-t0)**2 - 0.13*(logg-g0) + 0.13*(logg-g0)**2)\n",
    "    else:\n",
    "        # giants (RGB/AGB)\n",
    "        vmac = 3*(1.15 + 2.2e-5*(teff-t0) - 0.5e-7*(teff-t0)**2 - 0.1*(logg-g0) + 0.04*(logg-g0)**2 - 0.37*feh - 0.07*feh**2)\n",
    "\n",
    "    return vmac\n",
    "\n",
    "def estimate_vmac(teff, logg, feh, relation='GES'):\n",
    "    \"\"\"\n",
    "    Estimate Microturbulence velocity (Vmic) by using an empirical relation\n",
    "    considering the effective temperature, surface gravity and metallicity.\n",
    "\n",
    "    By default, the selected relation was constructed by Maria Bergemann\n",
    "    for the Gaia ESO Survey. Alternatively, \"relation='Doyle2014'\" implements\n",
    "    a relation for dwrafs (Doyle et al, 2014).\n",
    "    \"\"\"\n",
    "    if relation == 'Doyle2014':\n",
    "        vmac = _estimate_vmac_doyle2014(teff, logg, feh)\n",
    "    else:\n",
    "        vmac = _estimate_vmac_ges(teff, logg, feh)\n",
    "    vmac = float(\"%.2f\" % vmac)\n",
    "    return vmac\n",
    "\n",
    "### vmic\n",
    "def _estimate_vmic_ges(teff, logg, feh):\n",
    "    \"\"\"\n",
    "    Estimate Microturbulence velocity (Vmic) by using an empirical relation\n",
    "    considering the effective temperature, surface gravity and metallicity.\n",
    "\n",
    "    The relation was constructed based on the UVES Gaia ESO Survey iDR1 data,\n",
    "    results for the benchmark stars (Jofre et al. 2013),\n",
    "    and globular cluster data from external literature sources.\n",
    "\n",
    "    Source: http://great.ast.cam.ac.uk/GESwiki/GesWg/GesWg11/Microturbulence\n",
    "    \"\"\"\n",
    "    t0 = 5500\n",
    "    g0 = 4.0\n",
    "\n",
    "    if logg >= 3.5:\n",
    "        if teff >= 5000:\n",
    "            # main sequence and subgiants (RGB)\n",
    "            vmic = 1.05 + 2.51e-4*(teff-t0) + 1.5e-7*(teff-t0)**2 - 0.14*(logg-g0) - 0.05e-1*(logg-g0)**2 + 0.05*feh + 0.01*feh**2\n",
    "        else:\n",
    "            # main sequence\n",
    "            vmic = 1.05 + 2.51e-4*(5000-t0) + 1.5e-7*(5000-t0)**2 - 0.14*(logg-g0) - 0.05e-1*(logg-g0)**2 + 0.05*feh + 0.01*feh**2\n",
    "    else:\n",
    "        # giants (RGB/AGB)\n",
    "        vmic = 1.25 + 4.01e-4*(teff-t0) + 3.1e-7*(teff-t0)**2 - 0.14*(logg-g0) - 0.05e-1*(logg-g0)**2 + 0.05*feh + 0.01*feh**2\n",
    "    vmic = float(\"%.2f\" % vmic)\n",
    "    return vmic\n",
    "\n",
    "def _estimate_vmic_Bruntt2010(teff, logg, feh):\n",
    "    # https://ui.adsabs.harvard.edu/abs/2010MNRAS.405.1907B/abstract\n",
    "    t0 = 5700\n",
    "    g0 = 4.0\n",
    "\n",
    "    if logg < 4 or teff < 5000 or teff > 6500:\n",
    "        return np.nan\n",
    "\n",
    "    vmic = 1.01 + 4.5610e-4*(teff-t0) + 2.75e-7*(teff-t0)**2\n",
    "    \n",
    "    vmic = float(\"%.2f\" % vmic)\n",
    "    return vmic\n",
    "\n",
    "def estimate_vmic(teff, logg, feh, relation='GES'):\n",
    "    \"\"\"\n",
    "    Estimate Microturbulence velocity (Vmic) by using an empirical relation\n",
    "    considering the effective temperature, surface gravity and metallicity.\n",
    "\n",
    "    By default, the selected relation was constructed by Maria Bergemann\n",
    "    for the Gaia ESO Survey. Alternatively, \"relation='Doyle2014'\" implements\n",
    "    a relation for dwrafs (Doyle et al, 2014).\n",
    "    \"\"\"\n",
    "    if relation == 'Bruntt2010':\n",
    "        vmac = _estimate_vmic_Bruntt2010(teff, logg, feh)\n",
    "    else:\n",
    "        vmac = _estimate_vmic_ges(teff, logg, feh)\n",
    "    vmac = float(\"%.2f\" % vmac)\n",
    "    return vmac\n",
    "\n",
    "\n",
    "teff = 5500\n",
    "logg = 4.5\n",
    "feh = 0.0\n",
    "\n",
    "#vmac = estimate_vmac(teff, logg, feh)\n",
    "vmic = estimate_vmic(teff, logg, feh)\n",
    "\n",
    "#print(vmac,vmic)\n",
    "\n",
    "vmac = estimate_vmac(teff, logg, feh, relation='Doyle2014')\n",
    "#vmic = estimate_vmic(teff, logg, feh, relation='Bruntt2010')\n",
    "\n",
    "print(vmac,vmic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
